{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## Exercise 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output #1: The link to latest football score.\n",
      "Output #2: The link to latest football score. \n",
      "Output #3: The link to latest football score. \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "class TextManipulator:\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "\n",
    "    def remove_last_20_chars(self):\n",
    "        return self.text[:-20]\n",
    "\n",
    "    def remove_url_prefix(self):\n",
    "        url_start = self.text.find('https://')\n",
    "        return self.text[:url_start]\n",
    "\n",
    "    def remove_urls(self):\n",
    "        url_regex = r'https?://\\S+\\.\\S+'\n",
    "        return re.sub(url_regex, '', self.text)\n",
    "\n",
    "# Input text\n",
    "text = \"The link to latest football score. https://xyz.com/a/b\"\n",
    "\n",
    "# Create an instance of TextManipulator\n",
    "text_manipulator = TextManipulator(text)\n",
    "\n",
    "# Remove last 20 characters (basic)\n",
    "output1 = text_manipulator.remove_last_20_chars()\n",
    "print(f'Output #1: {output1}')\n",
    "\n",
    "# Remove URL prefix (prefix)\n",
    "output2 = text_manipulator.remove_url_prefix()\n",
    "print(f'Output #2: {output2}')\n",
    "\n",
    "# Remove URLs using regex (ready to serve method)\n",
    "output3 = text_manipulator.remove_urls()\n",
    "print(f'Output #3: {output3}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Maria \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_words_with_regex(text, regex = r'', doSplit = False):\n",
    "    if doSplit:\n",
    "        text = re.findall(regex, text)\n",
    "    return re.sub(regex, '', text)\n",
    "\n",
    "regex = r'\\b\\w*\\d\\w*\\b'\n",
    "# Input text\n",
    "text = \"Hello Maria whatsup123\"\n",
    "\n",
    "# Call the function to remove words with digits\n",
    "output = remove_words_with_regex(text,regex)\n",
    "\n",
    "# Print the output\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mado is very good with last ball six#six\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Mado is very good with last ball six #dhoni #six\"\n",
    "regex = r'\\s*#\\w+\\s'\n",
    "output = remove_words_with_regex(text,regex)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will be buying movie tickets for  4 adults\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "regex = r'(\\d+|\\D+)'\n",
    "text = \"I will be buying movie tickets for 4adults\"\n",
    "splitted = re.findall(regex, text)\n",
    "output = ' '.join(splitted)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>O'Sullivan keeps his powder dry\\n\\nWhen you ar...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>Millions buy MP3 players in US\\n\\nOne in 10 ad...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>Zambia confident and cautious\\n\\nZambia's tech...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>TV station refuses adoption show\\n\\nA TV stati...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>EU software patent law delayed\\n\\nControversia...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>Tsunami cost hits Jakarta shares\\n\\nThe stock ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>Chelsea denied by James heroics\\n\\nA brave def...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>Manics in charge of BBC 6 Music\\n\\nThe Manic S...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>EU software patent law faces axe\\n\\nThe Europe...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>Benitez deflects blame from Dudek\\n\\nLiverpool...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>'EU referendum could cost £80m'\\n\\nIt could co...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>Blind student 'hears in colour'\\n\\nA blind stu...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>PM apology over jailings\\n\\nTony Blair has apo...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>Kelly trails new discipline power\\n\\nTeachers ...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Go-ahead for Balkan oil pipeline\\n\\nAlbania, B...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Giant waves damage S Asia economy\\n\\nGovernmen...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>US interest rate rise expected\\n\\nUS interest ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>'Ultimate game' award for Doom 3\\n\\nSci-fi sho...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>Newcastle 2-1 Bolton\\n\\nKieron Dyer smashed ho...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>MPs to debate 'euthanasia laws'\\n\\nMPs are pre...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text         labels\n",
       "1666  O'Sullivan keeps his powder dry\\n\\nWhen you ar...          sport\n",
       "1870  Millions buy MP3 players in US\\n\\nOne in 10 ad...           tech\n",
       "1527  Zambia confident and cautious\\n\\nZambia's tech...          sport\n",
       "675   TV station refuses adoption show\\n\\nA TV stati...  entertainment\n",
       "2081  EU software patent law delayed\\n\\nControversia...           tech\n",
       "410   Tsunami cost hits Jakarta shares\\n\\nThe stock ...       business\n",
       "1451  Chelsea denied by James heroics\\n\\nA brave def...          sport\n",
       "616   Manics in charge of BBC 6 Music\\n\\nThe Manic S...  entertainment\n",
       "1837  EU software patent law faces axe\\n\\nThe Europe...           tech\n",
       "1571  Benitez deflects blame from Dudek\\n\\nLiverpool...          sport\n",
       "1286  'EU referendum could cost £80m'\\n\\nIt could co...       politics\n",
       "2146  Blind student 'hears in colour'\\n\\nA blind stu...           tech\n",
       "907   PM apology over jailings\\n\\nTony Blair has apo...       politics\n",
       "950   Kelly trails new discipline power\\n\\nTeachers ...       politics\n",
       "362   Go-ahead for Balkan oil pipeline\\n\\nAlbania, B...       business\n",
       "352   Giant waves damage S Asia economy\\n\\nGovernmen...       business\n",
       "401   US interest rate rise expected\\n\\nUS interest ...       business\n",
       "1994  'Ultimate game' award for Doom 3\\n\\nSci-fi sho...           tech\n",
       "1417  Newcastle 2-1 Bolton\\n\\nKieron Dyer smashed ho...          sport\n",
       "963   MPs to debate 'euthanasia laws'\\n\\nMPs are pre...       politics"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "sport            511\n",
       "business         510\n",
       "politics         417\n",
       "tech             401\n",
       "entertainment    386\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_samples = df.sample(3)\n",
    "texts = summarize_samples.text.to_list()\n",
    "labels = summarize_samples.labels.to_list(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Can Smith work Scottish wonders?\\n\\nThe worst kept secret in Scottish football was revealed on Thursday when Walter Smith was named as the new national manager.\\n\\nFrom the moment Berti Vogts' miserable tenure in charge of Scotland ended, the former Rangers and Everton boss has been the overwhelming favourite for the post. But is Smith the man for what must be one of the hardest jobs in football? The 56-year-old takes over at a time when the national side is in the doldrums. Scotland have not reached a major finals since the World Cup in 1998 and reaching Germany 2006 looks near impossible, having picked up just two points from the opening three games in the qualifying race. And the Fifa rankings see Scotland listed at an all time low of 77th, below the likes of Estonia, Ghana, Angola and Thailand. Scotland are not blessed with quality players with experience at the top level, so Smith will have to get the best out of meagre resources. Smith's track record make impressive reading and he is widely respected within the game. The man who was Alex Ferguson's assistant when Scotland played at the 1986 World Cup won seven league titles with Rangers. And his appointment has been widely endorsed by many of the games' top names, including Ferguson and Graeme Souness, who took him to Ibrox as his assistant in 1986. Characters like Souness, Ferguson and current Ibrox manager Alex McLeish all cite Smith's experience and his expansive knowledge of the Scottish game.\\n\\nMuch was made of Vogts' inability to express himself to the players and media. That will certainly not be the case with Smith. The former Dundee United and Dumbarton full-back is from the managerial old school - straight talking and never slow to let players know when he expects better (often with the use of some colourful invective). But it should be remembered Vogts came to Scotland with an impressive curriculum vitae - a World Cup winner as a player and a European Championships winner as a manager. Smith will inherit the same problems Vogts had - a callow squad of players with no exceptional talents. And it remains to be seen if Smith will experience the rash of call-offs that blighted so much of Vogts' preparation work. A fresh start for the Scottish national team was imperative and Smith is widely regarded as a safe pair of hands. But will a safe pair of hands be enough when the adroit hands of a magician might be required...\",\n",
       " 'Greek duo cleared in doping case\\n\\nSprinters Kostas Kenteris and Katerina Thanou have been cleared of doping offences by an independent tribunal.\\n\\nThe duo had been provisionally suspended by the IAAF for allegedly missing three drugs tests, including one on the eve of the Athens Olympics. But the Greek Athletics Federation tribunal has overturned the bans - a decision which the IAAF can now contest at the Court of Arbitration for Sport. The pair\\'s former coach, Christos Tzekos, has been banned for four years. Kenteris, 31, and Thanou, 30, had been charged with avoiding drug tests in Tel Aviv, Chicago and Athens and failing to notify anti-doping officials of their whereabouts before the Olympics. They withdrew from the Olympics after missing a drugs test at the Olympic Village on 12 August.\\n\\nThe pair then spent four days in a hospital, claiming they had been injured in a motorcycle crash. It was the International Olympic Committee\\'s demand that the IAAF investigate the affair that led to the hearing of the Greek tribunal. The head of that tribunal, Kostas Panagopoulos, said it had not been proven that the athletes refused to take the test in Athens. \"The charge cannot be substantiated,\" he said. \"In no way was he (Kenteris) informed to appear for a doping test. The same goes for Thanou.\" Kenteris\\'s lawyer, Gregory Ioannidis, said: \"The decision means Mr Kenteris has been exonerated of highly damaging and unfounded charges which have been extremely harmful for his career.\\n\\n\"He has consistently maintained his innocence and this was substantiated by further evidence we were able to submit to the tribunal following its deliberations in January. \"This evidence shows Mr Kenteris was never asked to submit to a test by the International Olympic Committee so he could not possibly have been guilty of deliberately avoiding one. It shows he has no case to answer. \"Mr Kenteris should now be given the opportunity he deserves to rebuild his career in the full knowledge that there is no stain on his character. \"He has suffered greatly throughout this ordeal that has exposed both himself and his family to enormous pressures.\" But the IAAF said it was \"very surprised\" by the verdict. Spokesman Nick Davies said: \"We note the decision of the Greek authorities with interest. \"Our doping review board will now consider the English version of the decision.\"',\n",
       " \"Beer giant swallows Russian firm\\n\\nBrewing giant Inbev has agreed to buy Alfa-Eco's stake in Sun Interbrew, Russia's second-largest brewer, for up to 259.7m euros ($353.3m; £183.75m).\\n\\nAlfa-Eco, the venture capital arm of Russian conglomerate Alfa Group, has a one-fifth stake in Sun Interbrew. The deal gives Inbev, the world's biggest beermaker, near-total control over the Russian brewer. Inbev bought out another partner in August 2004. Inbev brands include Bass, Stella Artois, Hoegaarden and Staropramen. It employs 77,000 people, running operations in over 30 countries across the Americas, Europe and Asia Pacific.\\n\\nThe Leuven-based brewery said it would own 97.3% of the voting shares and 98.8% of the non-voting shares of Sun Interbrew. The deal is expected to be completed in the first quarter of 2005. Inbev was formed in August 2004 when Belgium's Interbrew bought Brazilian brewer Ambev. Sun Interbrew, which employs 8,000 staff, owns breweries in eight Russian cities - Klin, Ivanovo, Saransk, Kursk, Volzhsky, Omsk, Perm and Novocheboksarsk. There are also three breweries in Ukraine, in the cities of Chernigov, Nikolaev and Kharkov.\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/python/3.10.13/lib/python3.10/site-packages (4.40.1)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from transformers) (2024.4.28)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def evaluate_time_and_summ(texts):\n",
    "    summs = []\n",
    "    start_time = datetime.now()  # Record the start time\n",
    "    for text in texts:\n",
    "        # Assuming pipe() is a function that returns a summary\n",
    "        summary = pipe(text, max_length=100, min_length=20)\n",
    "        summs.append(summary)\n",
    "        end_time = datetime.now()  # Record the end time\n",
    "        summs.append(end_time - start_time)\n",
    "\n",
    "    \n",
    "\n",
    "    return summs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = evaluate_time_and_summ(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'summary_text': 'Walter Smith has been named as the new manager of Scotland. The 56-year-old replaces Berti Vogts, who was sacked on Wednesday. Scotland have not reached a major finals since the World Cup in 1998.'}],\n",
       " datetime.timedelta(seconds=23, microseconds=389042),\n",
       " [{'summary_text': 'Kostas Kenteris and Katerina Thanou have been cleared of doping offences. The duo had been provisionally suspended by the IAAF for allegedly missing three drugs tests, including one on the eve of the Athens Olympics. But the Greek Athletics Federation tribunal has overturned the bans. The IAAF can now contest the decision at the Court of Arbitration for Sport.'}],\n",
       " datetime.timedelta(seconds=37, microseconds=377484),\n",
       " [{'summary_text': \"Alfa-Eco, the venture capital arm of Russian conglomerate Alfa Group, has a one-fifth stake in Sun Interbrew. The deal gives Inbev, the world's biggest beermaker, near-total control over the Russian brewer.\"}],\n",
       " datetime.timedelta(seconds=46, microseconds=668003)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_path = './model'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('zero-shot-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for text in texts:\n",
    "    results.append(classifier(text, candidate_labels = labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred : ['politics', 'sport', 'politics'] | Actualy: ['politics', 'sport', 'politics']\n"
     ]
    }
   ],
   "source": [
    "for text, label in zip(results, labels):\n",
    "    pred_label = text['labels'][0]    \n",
    "    print(f'Pred : {pred_label} | Actualy: {label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People are using AI chatbots to fill junk websites with AI-generated text that attracts paying advertisers, according to a new report from the media research organization NewsGuard that was shared exclusively with MIT Technology Review. Over 140 major brands are paying for ads that end up on unreliable AI-written sites, likely without their knowledge. Ninety percent of the ads from major brands found on these AI-generated news sites were served by Google, though the company’s own policies prohibit sites from placing Google-served ads on pages that include “spammy automatically generated content.” The practice threatens to hasten the arrival of a glitchy, spammy internet that is overrun by AI-generated content, as well as wasting massive amounts of ad money.\n",
      "\n",
      "A new report finds that sites run with AI-generated content serve ads from major brands, which mostly come from Google. Some of those sites contained dangerous misinformation. And this is just getting started. More could be on the way. \"The opaque nature of programmatic advertising has inadvertently turned major brands into unwitting supporters.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('data/summary-1-flan-ul2--article1.txt', 'r') as file:\n",
    "    reference_summary = file.read()\n",
    "with open('data/summary-2-flan-ul2--article1.txt', 'r') as file:\n",
    "    candidate_summary = file.read()\n",
    "print(reference_summary)\n",
    "print(candidate_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from nltk) (2024.4.28)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.13/lib/python3.10/site-packages (from nltk) (4.66.4)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: click, nltk\n",
      "Successfully installed click-8.1.7 nltk-3.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score 1.0025117266892697e-231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "bleu = sentence_bleu(reference_summary, candidate_summary)\n",
    "print(f'BLEU score {bleu}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
